# train_model.py
import os
import sys
import math
import joblib
import numpy as np
import pandas as pd
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error

# ===== ê²½ë¡œ/íŒŒì¼ =====
STATIC_FILE   = "ML_static_dataset.csv"   # ì •ì (ê³¼ê±°) ë°ì´í„°
DYNAMIC_FILE  = "ML_asos_dataset.csv"     # ë™ì (ì‚¬ìš©ì ì…ë ¥/ìµœì‹ ) ë°ì´í„° (ì—†ì–´ë„ ë¨)
MODEL_FILE    = "trained_model.pkl"
FEATURE_FILE  = "feature_names.pkl"

# í•™ìŠµì— ì‚¬ìš©í•  í”¼ì²˜ "ìˆœì„œ ê³ ì •" â€” predict_from_weatherì™€ 100% ë™ì¼
FEATURE_ORDER = [
    "ìµœê³ ì²´ê°ì˜¨ë„(Â°C)",
    "ìµœê³ ê¸°ì˜¨(Â°C)",
    "í‰ê· ê¸°ì˜¨(Â°C)",
    "ìµœì €ê¸°ì˜¨(Â°C)",
    "í‰ê· ìƒëŒ€ìŠµë„(%)",
]
TARGET_COL = "í™˜ììˆ˜"

def _read_csv_any(path: str) -> pd.DataFrame:
    """utf-8-sig ìš°ì„ , ì‹¤íŒ¨ ì‹œ cp949ë¡œ ì¬ì‹œë„"""
    try:
        return pd.read_csv(path, encoding="utf-8-sig")
    except UnicodeDecodeError:
        return pd.read_csv(path, encoding="cp949")

def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = df.columns.str.strip().str.replace("\n", "", regex=False).str.replace(" ", "", regex=False)
    # 'ì¼ì' ë§Œë“¤ê¸°: ì—‘ì…€ ë‚ ì§œ or ë¬¸ìì—´ ë‚ ì§œ ëª¨ë‘ í—ˆìš©
    if "ì¼ì" not in df.columns:
        if "ì¼ì‹œ" in df.columns:
            # ìˆ«ì(ì—‘ì…€ ì§ë ¬) â†’ ë‚ ì§œ
            if pd.api.types.is_numeric_dtype(df["ì¼ì‹œ"]):
                df["ì¼ì"] = (pd.to_datetime("1899-12-30") + pd.to_timedelta(df["ì¼ì‹œ"], unit="D")).dt.strftime("%Y-%m-%d")
            else:
                df["ì¼ì"] = pd.to_datetime(df["ì¼ì‹œ"], errors="coerce").dt.strftime("%Y-%m-%d")
        # ì§€ì—­ ì»¬ëŸ¼ í†µì¼
    if "ì§€ì—­" not in df.columns:
        for cand in ["ê´‘ì—­ìì¹˜ë‹¨ì²´", "ì‹œë„"]:
            if cand in df.columns:
                df["ì§€ì—­"] = df[cand]
                break

    # ë¶ˆí•„ìš” ì—´ ì œê±°
    drop_cols = [c for c in ["ì¼ì‹œ", "ê´‘ì—­ìì¹˜ë‹¨ì²´", "ì‹œë„"] if c in df.columns]
    if drop_cols:
        df = df.drop(columns=drop_cols)
    return df

def _coerce_numeric(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    num_cols = FEATURE_ORDER + [TARGET_COL]
    for c in num_cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    # RHëŠ” 0~100 clip (í‰ê· ìƒëŒ€ìŠµë„)
    if "í‰ê· ìƒëŒ€ìŠµë„(%)" in df.columns:
        df["í‰ê· ìƒëŒ€ìŠµë„(%)"] = df["í‰ê· ìƒëŒ€ìŠµë„(%)"].clip(lower=0, upper=100)
    return df

def _aggregate(df: pd.DataFrame) -> pd.DataFrame:
    # ê°™ì€ ì¼ì/ì§€ì—­ì— ë‹¤ì¤‘ í–‰ â†’ ê¸°ìƒ ë³€ìˆ˜ëŠ” í‰ê· , í™˜ììˆ˜ëŠ” í•©
    need = ["ì¼ì", "ì§€ì—­"] + FEATURE_ORDER + [TARGET_COL]
    missing = [c for c in need if c not in df.columns]
    if missing:
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")

    df = df.dropna(subset=["ì¼ì", "ì§€ì—­"])
    # ìˆ«ìí˜• ê²°ì¸¡ ì œê±°
    df = df.dropna(subset=[c for c in FEATURE_ORDER + [TARGET_COL] if c in df.columns])

    grouped = df.groupby(["ì¼ì", "ì§€ì—­"], as_index=False).agg({
        "ìµœê³ ì²´ê°ì˜¨ë„(Â°C)": "mean",
        "ìµœê³ ê¸°ì˜¨(Â°C)": "mean",
        "í‰ê· ê¸°ì˜¨(Â°C)": "mean",
        "ìµœì €ê¸°ì˜¨(Â°C)": "mean",
        "í‰ê· ìƒëŒ€ìŠµë„(%)": "mean",
        "í™˜ììˆ˜": "sum",
    })
    return grouped

def main():
    print("ğŸ“‚ CWD:", os.getcwd())
    print("ğŸ“„ íŒŒì¼:", os.listdir())

    if not os.path.exists(STATIC_FILE):
        print(f"âŒ ì •ì  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {STATIC_FILE}")
        sys.exit(1)

    # 1) ì •ì  ë°ì´í„°
    df_static = _read_csv_any(STATIC_FILE)
    df_static = _normalize_columns(df_static)
    df_static = _coerce_numeric(df_static)
    print(f"âœ… ì •ì  ë°ì´í„° ë¡œë“œ: {df_static.shape}")

    # 2) ë™ì  ë°ì´í„°(ì„ íƒ)
    if os.path.exists(DYNAMIC_FILE):
        df_dyn = _read_csv_any(DYNAMIC_FILE)
        df_dyn = _normalize_columns(df_dyn)
        df_dyn = _coerce_numeric(df_dyn)
        print(f"âœ… ë™ì  ë°ì´í„° ë¡œë“œ: {df_dyn.shape}")
        df_all = pd.concat([df_static, df_dyn], ignore_index=True)
    else:
        print("âš ï¸ ë™ì  ë°ì´í„° ì—†ìŒ â†’ ì •ì  ë°ì´í„°ë§Œ ì‚¬ìš©")
        df_all = df_static.copy()

    # 3) ì§‘ê³„
    df_all = _aggregate(df_all)
    print(f"ğŸ“Š ì§‘ê³„ ì™„ë£Œ: {df_all.shape}")

    # 4) í•™ìŠµ ë°ì´í„° êµ¬ì„±
    X = df_all[FEATURE_ORDER].astype(np.float32)
    y = df_all[TARGET_COL].astype(np.float32)

    if len(df_all) < 20:
        print(f"âš ï¸ í‘œë³¸ {len(df_all)} â†’ í™€ë“œì•„ì›ƒ í‰ê°€ ëŒ€ì‹  í›ˆë ¨ì…‹ ì§€í‘œë§Œ ì¶œë ¥")
        X_train, X_test, y_train, y_test = X, X, y, y
    else:
        # ë‚ ì§œ/ì§€ì—­ ì„ì—¬ìˆìœ¼ë‹ˆ ëœë¤ ë¶„í• (ì¬í˜„ì„± ê³ ì •)
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

    # 5) ëª¨ë¸ í•™ìŠµ
    model = XGBRegressor(
        n_estimators=200,
        max_depth=4,
        learning_rate=0.1,
        subsample=0.9,
        colsample_bytree=0.9,
        random_state=42,
        n_jobs=-1,
    )
    model.fit(X_train, y_train)

    # 6) ì„±ëŠ¥ í‰ê°€
    def _eval(split, X_, y_):
        pred = model.predict(X_)
        r2 = r2_score(y_, pred)
        rmse = math.sqrt(mean_squared_error(y_, pred))
        print(f"ğŸ“ˆ {split} â€” RÂ²: {r2:.4f} | RMSE: {rmse:.4f}")

    _eval("Train", X_train, y_train)
    if X_test is not X_train:
        _eval("Test", X_test, y_test)

    # 7) ì•„í‹°íŒ©íŠ¸ ì €ì¥
    joblib.dump(model, MODEL_FILE)
    joblib.dump(FEATURE_ORDER, FEATURE_FILE)
    print(f"\nâœ… ì €ì¥ ì™„ë£Œ â†’ {MODEL_FILE}, {FEATURE_FILE}")
    print(f"ğŸ§  ì‚¬ìš© í”¼ì²˜(ìˆœì„œ ê³ ì •): {FEATURE_ORDER}")

if __name__ == "__main__":
    main()
